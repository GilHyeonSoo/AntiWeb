from flask import Flask, jsonify, request
from flask_cors import CORS
from youtube_transcript_api import YouTubeTranscriptApi
from openai import OpenAI
from dotenv import load_dotenv
import traceback
import re
import os
import json
from pathlib import Path
import cache_manager

# Load environment variables from parent directory (.env in project root)
env_path = Path(__file__).parent.parent / '.env'
load_dotenv(dotenv_path=env_path)
# Also try local .env if exists
load_dotenv()

app = Flask(__name__)
CORS(app, origins=['http://localhost:5173', 'http://localhost:3000', 'http://127.0.0.1:5173'])

# Create YouTube API instance
ytt_api = YouTubeTranscriptApi()

# DeepSeek API setup (OpenAI compatible)
DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY')
deepseek_client = None

if DEEPSEEK_API_KEY and DEEPSEEK_API_KEY != 'your_deepseek_api_key_here':
    deepseek_client = OpenAI(
        api_key=DEEPSEEK_API_KEY,
        base_url="https://api.deepseek.com"
    )
    print("âœ… DeepSeek AI API configured")
else:
    print("âš ï¸ DeepSeek API key not configured. Question generation will be unavailable.")

def format_transcript_readable(transcript_list, pause_threshold=2.0):
    """Format transcript into readable paragraphs based on pauses."""
    if not transcript_list:
        return ""
    
    paragraphs = []
    current_paragraph = []
    
    for i, item in enumerate(transcript_list):
        text = item['text'].strip()
        if not text:
            continue
        current_paragraph.append(text)
        
        if i < len(transcript_list) - 1:
            current_end = item['start'] + item['duration']
            next_start = transcript_list[i + 1]['start']
            pause = next_start - current_end
            
            if pause >= pause_threshold:
                paragraph_text = ' '.join(current_paragraph)
                paragraphs.append(paragraph_text)
                current_paragraph = []
    
    if current_paragraph:
        paragraphs.append(' '.join(current_paragraph))
    
    result = '\n\n'.join(paragraphs)
    result = re.sub(r' +', ' ', result)
    result = re.sub(r'\n{3,}', '\n\n', result)
    
    return result

@app.route('/api/health', methods=['GET'])
def health_check():
    return jsonify({
        'status': 'ok',
        'message': 'GenGen Python API Server is running',
        'deepseekConfigured': deepseek_client is not None
    })

@app.route('/api/transcript/<video_id>', methods=['GET'])
def get_transcript(video_id):
    preferred_lang = request.args.get('lang', 'ko')
    format_type = request.args.get('format', 'readable')
    
    if not video_id:
        return jsonify({'success': False, 'error': 'ì˜ìƒ IDê°€ í•„ìš”í•©ë‹ˆë‹¤.'}), 400
    
    try:
        print(f"\n=== Fetching transcript: {video_id} ===")
        
        languages_to_try = [preferred_lang, 'ko', 'en']
        
        try:
            transcript_data = ytt_api.fetch(video_id, languages=languages_to_try)
            language_used = preferred_lang
        except Exception:
            try:
                transcript_data = ytt_api.fetch(video_id)
                language_used = 'auto'
            except Exception as e2:
                raise e2
        
        transcript_list = []
        for snippet in transcript_data:
            transcript_list.append({
                'text': snippet.text,
                'start': snippet.start,
                'duration': snippet.duration
            })
        
        if not transcript_list:
            return jsonify({'success': False, 'error': 'ìë§‰ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.'}), 404
        
        raw_text = ' '.join([item['text'] for item in transcript_list])
        raw_text = ' '.join(raw_text.split())
        
        if format_type == 'readable':
            formatted_text = format_transcript_readable(transcript_list)
        else:
            formatted_text = raw_text
        
        text_with_timestamps = '\n'.join([
            f"[{int(item['start'] // 60)}:{int(item['start'] % 60):02d}] {item['text']}"
            for item in transcript_list
        ])
        
        print(f"âœ… Success: {len(transcript_list)} segments")
        
        return jsonify({
            'success': True,
            'videoId': video_id,
            'language': language_used,
            'text': formatted_text,
            'rawText': raw_text,
            'textWithTimestamps': text_with_timestamps,
            'segments': len(transcript_list)
        })
        
    except Exception as e:
        error_str = str(e)
        print(f"Error: {error_str}")
        
        if 'disabled' in error_str.lower():
            return jsonify({'success': False, 'error': 'ìë§‰ì´ ë¹„í™œì„±í™”ëœ ì˜ìƒì…ë‹ˆë‹¤.'}), 404
        elif 'unavailable' in error_str.lower():
            return jsonify({'success': False, 'error': 'ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404
        else:
            return jsonify({'success': False, 'error': f'ì˜¤ë¥˜: {error_str}'}), 500


# ============ Subtitle Formatting with DeepSeek ============

@app.route('/api/format-subtitle', methods=['POST'])
def format_subtitle():
    """Format raw subtitle text into readable markdown using DeepSeek."""
    if not deepseek_client:
        return jsonify({
            'success': False,
            'error': 'DeepSeek API key not configured'
        }), 500
    
    data = request.get_json()
    if not data or 'text' not in data:
        return jsonify({
            'success': False,
            'error': 'No text provided'
        }), 400
    
    raw_text = data['text']
    
    if not raw_text.strip():
        return jsonify({
            'success': False,
            'error': 'Empty text'
        }), 400
    
    # Check cache first
    cache_key = cache_manager.generate_cache_key('subtitle', raw_text[:500])
    cached_result = cache_manager.get_cached(cache_key)
    
    if cached_result:
        print(f"ğŸ“¦ Returning cached formatted subtitle")
        return jsonify({
            'success': True,
            'formattedText': cached_result,
            'cached': True
        })
    
    try:
        prompt = f"""ë‹¤ìŒì€ ìœ íŠœë¸Œ ì˜ìƒì˜ ìë§‰ì…ë‹ˆë‹¤. ì´ ìë§‰ì„ ì½ê¸° ì‰½ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”.

ê·œì¹™:
1. ë¬¸ì¥ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ë¶™ì—¬ì„œ ì½ê¸° ì¢‹ê²Œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
2. ì£¼ì œë³„ë¡œ ë‹¨ë½ì„ ë‚˜ëˆ ì£¼ì„¸ìš”.
3. ì¤‘ìš”í•œ í•µì‹¬ ë‚´ìš©ì€ **êµµì€ ê¸€ì”¨**ë¡œ ê°•ì¡°í•´ì£¼ì„¸ìš”.
4. ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”.
5. ë¶ˆí•„ìš”í•œ ë°˜ë³µì´ë‚˜ ë§ë”ë“¬ì€ ì œê±°í•´ì£¼ì„¸ìš”.
6. ë‚´ìš©ì„ ìš”ì•½í•˜ì§€ ë§ê³ , ì›ë˜ ë‚´ìš©ì„ ìµœëŒ€í•œ ìœ ì§€í•˜ë©´ì„œ ì •ë¦¬í•´ì£¼ì„¸ìš”.

ìë§‰:
{raw_text}

ìœ„ ìë§‰ì„ ì½ê¸° ì¢‹ê²Œ ì •ë¦¬í•œ ë§ˆí¬ë‹¤ìš´:"""

        response = deepseek_client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ì •ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ìë§‰ì„ ì½ê¸° ì¢‹ê²Œ ì •ë¦¬í•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=4000
        )
        
        formatted_text = response.choices[0].message.content.strip()
        
        print(f"âœ… Formatted subtitle ({len(raw_text)} -> {len(formatted_text)} chars)")
        
        # Cache the result
        cache_manager.set_cache(cache_key, formatted_text)
        
        return jsonify({
            'success': True,
            'formattedText': formatted_text
        })
        
    except Exception as e:
        print(f"âŒ Subtitle formatting error: {e}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': f'ìë§‰ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }), 500


# Question generation prompts
QUESTION_PROMPTS = {
    'multiple_choice': '''ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **ì‹¤ì œ ì‹œí—˜ì— ë‚˜ì˜¬ ë²•í•œ** ê°ê´€ì‹ ë¬¸ì œë¥¼ {count}ê°œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ë¬¸ì œ ì¶œì œ ê°€ì´ë“œë¼ì¸:
- í•µì‹¬ ê°œë…ê³¼ ì¤‘ìš”í•œ ë‚´ìš©ì„ ë¬»ëŠ” ë¬¸ì œë¥¼ ì¶œì œí•˜ì„¸ìš”
- ë‹¨ìˆœ ì•”ê¸°ë³´ë‹¤ëŠ” ì´í•´ë„ë¥¼ í‰ê°€í•˜ëŠ” ë¬¸ì œë¥¼ ë§Œë“œì„¸ìš”
- ì˜¤ë‹µ ì„ íƒì§€ë„ ê·¸ëŸ´ë“¯í•˜ê²Œ ë§Œë“¤ì–´ ë³€ë³„ë ¥ì„ ë†’ì´ì„¸ìš”
- ì‹¤ì œ í•™êµ ì‹œí—˜ì´ë‚˜ ìê²©ì¦ ì‹œí—˜ ìŠ¤íƒ€ì¼ë¡œ ì¶œì œí•˜ì„¸ìš”

ê° ë¬¸ì œëŠ” ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
{{
  "question": "ë¬¸ì œ ë‚´ìš©",
  "options": ["ì„ íƒì§€1", "ì„ íƒì§€2", "ì„ íƒì§€3", "ì„ íƒì§€4"],
  "answer": 0,  // ì •ë‹µ ì¸ë±ìŠ¤ (0ë¶€í„° ì‹œì‘)
  "explanation": "ì •ë‹µ í•´ì„¤"
}}

í…ìŠ¤íŠ¸:
{text}

ìœ„ í…ìŠ¤íŠ¸ì— ëŒ€í•œ {count}ê°œì˜ ê°ê´€ì‹ ë¬¸ì œë¥¼ JSON ë°°ì—´ í˜•íƒœë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ JSONë§Œ ì‘ë‹µí•˜ì„¸ìš”.
''',
    
    'short_answer': '''ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **ì‹¤ì œ ì‹œí—˜ì— ë‚˜ì˜¬ ë²•í•œ** ë‹¨ë‹µí˜• ë¬¸ì œë¥¼ {count}ê°œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ë¬¸ì œ ì¶œì œ ê°€ì´ë“œë¼ì¸:
- í•µì‹¬ ìš©ì–´, ì •ì˜, ì¤‘ìš” ê°œë…ì„ ë¬»ëŠ” ë¬¸ì œë¥¼ ì¶œì œí•˜ì„¸ìš”
- ëª…í™•í•˜ê³  ê°„ê²°í•œ ì •ë‹µì´ ë‚˜ì˜¬ ìˆ˜ ìˆëŠ” ë¬¸ì œë¥¼ ë§Œë“œì„¸ìš”
- ì‹¤ì œ í•™êµ ì‹œí—˜ì´ë‚˜ ìê²©ì¦ ì‹œí—˜ì—ì„œ ë³¼ ìˆ˜ ìˆëŠ” ìŠ¤íƒ€ì¼ë¡œ ì¶œì œí•˜ì„¸ìš”

ê° ë¬¸ì œëŠ” ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
{{
  "question": "ë¬¸ì œ ë‚´ìš©",
  "answer": "ì •ë‹µ",
  "explanation": "ì •ë‹µ í•´ì„¤"
}}

í…ìŠ¤íŠ¸:
{text}

ìœ„ í…ìŠ¤íŠ¸ì— ëŒ€í•œ {count}ê°œì˜ ë‹¨ë‹µí˜• ë¬¸ì œë¥¼ JSON ë°°ì—´ í˜•íƒœë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ JSONë§Œ ì‘ë‹µí•˜ì„¸ìš”.
''',

    'true_false': '''ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **ì‹¤ì œ ì‹œí—˜ì— ë‚˜ì˜¬ ë²•í•œ** O/X(ì°¸/ê±°ì§“) ë¬¸ì œë¥¼ {count}ê°œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ë¬¸ì œ ì¶œì œ ê°€ì´ë“œë¼ì¸:
- ì¤‘ìš”í•œ ê°œë…ì˜ ì •í™•í•œ ì´í•´ë¥¼ í™•ì¸í•˜ëŠ” ë¬¸ì œë¥¼ ì¶œì œí•˜ì„¸ìš”
- ë¯¸ë¬˜í•œ ì°¨ì´ë‚˜ í”í•œ ì˜¤ê°œë…ì„ í™œìš©í•œ ë¬¸ì œë¥¼ ë§Œë“œì„¸ìš”
- ì°¸/ê±°ì§“ì´ ëª…í™•íˆ êµ¬ë¶„ë˜ëŠ” ì§„ìˆ ë¡œ ì‘ì„±í•˜ì„¸ìš”
- ì‹¤ì œ ì‹œí—˜ì—ì„œ ìì£¼ ì¶œì œë˜ëŠ” íŒ¨í„´ìœ¼ë¡œ ë§Œë“œì„¸ìš”

ê° ë¬¸ì œëŠ” ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
{{
  "question": "ë¬¸ì œ ë‚´ìš© (ì°¸ ë˜ëŠ” ê±°ì§“ìœ¼ë¡œ ë‹µí•  ìˆ˜ ìˆëŠ” ì§„ìˆ )",
  "answer": true,  // true ë˜ëŠ” false
  "explanation": "ì •ë‹µ í•´ì„¤"
}}

í…ìŠ¤íŠ¸:
{text}

ìœ„ í…ìŠ¤íŠ¸ì— ëŒ€í•œ {count}ê°œì˜ O/X ë¬¸ì œë¥¼ JSON ë°°ì—´ í˜•íƒœë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ JSONë§Œ ì‘ë‹µí•˜ì„¸ìš”.
''',

    'fill_blank': '''ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **ì‹¤ì œ ì‹œí—˜ì— ë‚˜ì˜¬ ë²•í•œ** ë¹ˆì¹¸ ì±„ìš°ê¸° ë¬¸ì œë¥¼ {count}ê°œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ë¬¸ì œ ì¶œì œ ê°€ì´ë“œë¼ì¸:
- í•µì‹¬ ìš©ì–´ë‚˜ ì¤‘ìš” ê°œë…ì´ ë¹ˆì¹¸ì´ ë˜ë„ë¡ ë¬¸ì œë¥¼ ì¶œì œí•˜ì„¸ìš”
- ë¬¸ë§¥ì„ í†µí•´ ì •ë‹µì„ ìœ ì¶”í•  ìˆ˜ ìˆì§€ë§Œ, ì •í™•í•œ ì§€ì‹ì´ í•„ìš”í•œ ë¬¸ì œë¥¼ ë§Œë“œì„¸ìš”
- ì‹¤ì œ ì‹œí—˜ì—ì„œ ìì£¼ ë‚˜ì˜¤ëŠ” í˜•íƒœë¡œ ì¶œì œí•˜ì„¸ìš”

ê° ë¬¸ì œëŠ” ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
{{
  "question": "ë¬¸ì¥ì—ì„œ ì¤‘ìš”í•œ ë¶€ë¶„ì„ ___ë¡œ í‘œì‹œí•œ ë¬¸ì œ",
  "answer": "ë¹ˆì¹¸ì— ë“¤ì–´ê°ˆ ì •ë‹µ",
  "explanation": "ì •ë‹µ í•´ì„¤"
}}

í…ìŠ¤íŠ¸:
{text}

ìœ„ í…ìŠ¤íŠ¸ì— ëŒ€í•œ {count}ê°œì˜ ë¹ˆì¹¸ ì±„ìš°ê¸° ë¬¸ì œë¥¼ JSON ë°°ì—´ í˜•íƒœë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ JSONë§Œ ì‘ë‹µí•˜ì„¸ìš”.
''',

    'math': '''ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **ì‹¤ì œ ì‹œí—˜ì— ë‚˜ì˜¬ ë²•í•œ** ìˆ˜í•™ ë¬¸ì œë¥¼ {count}ê°œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ë¬¸ì œ ì¶œì œ ê°€ì´ë“œë¼ì¸:
- í…ìŠ¤íŠ¸ì—ì„œ ë‹¤ë£¨ëŠ” ìˆ˜í•™ì  ê°œë…ì„ í™œìš©í•œ ë¬¸ì œë¥¼ ì¶œì œí•˜ì„¸ìš”
- ìˆ˜ì‹ì€ ë°˜ë“œì‹œ LaTeX ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì„¸ìš” (ì¸ë¼ì¸: $ìˆ˜ì‹$, ë¸”ë¡: $$ìˆ˜ì‹$$)
- ê³„ì‚° ë¬¸ì œ, ì¦ëª… ë¬¸ì œ, ì‘ìš© ë¬¸ì œ ë“± ë‹¤ì–‘í•œ ìœ í˜•ìœ¼ë¡œ ì¶œì œí•˜ì„¸ìš”
- í’€ì´ ê³¼ì •ì´ í•„ìš”í•œ ë¬¸ì œë¥¼ ë§Œë“œì„¸ìš”
- ì‹¤ì œ ìˆ˜í•™ ì‹œí—˜ì—ì„œ ë³¼ ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ì¶œì œí•˜ì„¸ìš”

ê° ë¬¸ì œëŠ” ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
{{
  "question": "ìˆ˜í•™ ë¬¸ì œ ë‚´ìš© (LaTeX ìˆ˜ì‹ í¬í•¨)",
  "answer": "ì •ë‹µ (LaTeX ìˆ˜ì‹ìœ¼ë¡œ í‘œí˜„)",
  "explanation": "í’€ì´ ê³¼ì • (LaTeX ìˆ˜ì‹ìœ¼ë¡œ ë‹¨ê³„ë³„ ì„¤ëª…)"
}}

ì˜ˆì‹œ:
{{
  "question": "ë‹¤ìŒ ì´ì°¨ë°©ì •ì‹ì˜ í•´ë¥¼ êµ¬í•˜ì‹œì˜¤: $x^2 - 5x + 6 = 0$",
  "answer": "$x = 2$ ë˜ëŠ” $x = 3$",
  "explanation": "ì¸ìˆ˜ë¶„í•´í•˜ë©´ $(x-2)(x-3) = 0$ì´ë¯€ë¡œ $x = 2$ ë˜ëŠ” $x = 3$"
}}

í…ìŠ¤íŠ¸:
{text}

ìœ„ í…ìŠ¤íŠ¸ì— ëŒ€í•œ {count}ê°œì˜ ìˆ˜í•™ ë¬¸ì œë¥¼ JSON ë°°ì—´ í˜•íƒœë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ JSONë§Œ ì‘ë‹µí•˜ì„¸ìš”.
'''
}

@app.route('/api/generate-questions', methods=['POST'])
def generate_questions():
    """Generate questions using DeepSeek AI"""
    
    if not deepseek_client:
        return jsonify({
            'success': False,
            'error': 'DeepSeek APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— DEEPSEEK_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.'
        }), 503
    
    data = request.get_json()
    
    if not data:
        return jsonify({'success': False, 'error': 'ìš”ì²­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'}), 400
    
    text = data.get('text', '')
    question_type = data.get('type', 'multiple_choice')
    count = data.get('count', 5)
    
    if not text:
        return jsonify({'success': False, 'error': 'í…ìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.'}), 400
    
    if question_type not in QUESTION_PROMPTS:
        return jsonify({'success': False, 'error': f'ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¬¸ì œ ìœ í˜•ì…ë‹ˆë‹¤: {question_type}'}), 400
    
    # Limit text length to avoid API limits (roughly 8000 tokens)
    max_chars = 15000
    if len(text) > max_chars:
        text = text[:max_chars] + "..."
    
    # Check cache first
    cache_key = cache_manager.generate_cache_key('questions', text[:500], question_type, count)
    cached_result = cache_manager.get_cached(cache_key)
    
    if cached_result:
        print(f"ğŸ“¦ Returning cached questions")
        return jsonify({
            'success': True,
            'questions': cached_result['questions'],
            'type': cached_result['type'],
            'count': cached_result['count'],
            'cached': True
        })
    
    try:
        print(f"\n=== Generating {count} {question_type} questions ===")
        print(f"Text length: {len(text)} chars")
        
        prompt = QUESTION_PROMPTS[question_type].format(text=text, count=count)
        
        response = deepseek_client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ í•™ìŠµì— ë„ì›€ì´ ë˜ëŠ” ë¬¸ì œë¥¼ ë§Œë“­ë‹ˆë‹¤. í•­ìƒ ìˆœìˆ˜í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=4000
        )
        
        result_text = response.choices[0].message.content.strip()
        print(f"AI Response length: {len(result_text)} chars")
        
        # Parse JSON from response
        # Try to extract JSON array from the response
        json_match = re.search(r'\[[\s\S]*\]', result_text)
        if json_match:
            result_text = json_match.group()
        
        try:
            questions = json.loads(result_text)
        except json.JSONDecodeError:
            # Try to fix common JSON issues
            result_text = result_text.replace("'", '"')
            result_text = re.sub(r',\s*]', ']', result_text)
            result_text = re.sub(r',\s*}', '}', result_text)
            questions = json.loads(result_text)
        
        print(f"âœ… Generated {len(questions)} questions")
        
        # Cache the result
        cache_manager.set_cache(cache_key, {
            'questions': questions,
            'type': question_type,
            'count': len(questions)
        })
        
        return jsonify({
            'success': True,
            'questions': questions,
            'type': question_type,
            'count': len(questions)
        })
        
    except json.JSONDecodeError as e:
        print(f"JSON Parse Error: {e}")
        print(f"Response was: {result_text[:500]}...")
        return jsonify({
            'success': False,
            'error': 'AI ì‘ë‹µì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'
        }), 500
        
    except Exception as e:
        print(f"Error: {e}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': f'ë¬¸ì œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }), 500


# ============ PDF OCR with Gemini API ============

# Gemini API setup
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')

if GEMINI_API_KEY and GEMINI_API_KEY != 'your_gemini_api_key_here':
    print("âœ… Gemini API configured for PDF OCR")
else:
    print("âš ï¸ Gemini API key not configured. PDF OCR will be unavailable.")


@app.route('/api/pdf/check', methods=['GET'])
def check_pdf_service():
    """Check if PDF OCR service is available."""
    from pdf_processor import check_dependencies
    
    issues = check_dependencies()
    has_api_key = bool(GEMINI_API_KEY and GEMINI_API_KEY != 'your_gemini_api_key_here')
    
    if not has_api_key:
        issues.append("GEMINI_API_KEY not configured")
    
    return jsonify({
        'available': len(issues) == 0 and has_api_key,
        'hasApiKey': has_api_key,
        'issues': issues
    })


@app.route('/api/pdf/extract', methods=['POST'])
def extract_pdf():
    """Extract text from PDF, PPTX, or DOCX files."""
    if not GEMINI_API_KEY or GEMINI_API_KEY == 'your_gemini_api_key_here':
        return jsonify({
            'success': False,
            'error': 'Gemini API key not configured'
        }), 500
    
    # Check if file was uploaded
    if 'file' not in request.files:
        return jsonify({
            'success': False,
            'error': 'No file uploaded'
        }), 400
    
    file = request.files['file']
    
    if file.filename == '':
        return jsonify({
            'success': False,
            'error': 'No file selected'
        }), 400
    
    filename_lower = file.filename.lower()
    
    # Check file extension
    if not (filename_lower.endswith('.pdf') or 
            filename_lower.endswith('.pptx') or 
            filename_lower.endswith('.docx')):
        return jsonify({
            'success': False,
            'error': 'Supported formats: PDF, PPTX, DOCX'
        }), 400
    
    try:
        file_bytes = file.read()
        print(f"ğŸ“„ Processing file: {file.filename} ({len(file_bytes)} bytes)")
        
        # Route to appropriate processor based on file type
        if filename_lower.endswith('.pdf'):
            from pdf_processor import process_pdf
            result = process_pdf(file_bytes, GEMINI_API_KEY)
            count_key = 'page_count'
            count_name = 'pageCount'
            
        elif filename_lower.endswith('.pptx'):
            from pdf_processor import process_pptx
            result = process_pptx(file_bytes, GEMINI_API_KEY)
            count_key = 'slide_count'
            count_name = 'slideCount'
            
        elif filename_lower.endswith('.docx'):
            from pdf_processor import extract_docx_text
            result = extract_docx_text(file_bytes)
            count_key = 'paragraph_count'
            count_name = 'paragraphCount'
        
        if result['success']:
            print(f"âœ… File processed successfully ({result.get(count_key, 0)} {count_key})")
            return jsonify({
                'success': True,
                'text': result['text'],
                count_name: result.get(count_key, 0)
            })
        else:
            print(f"âŒ PDF processing failed: {result.get('error')}")
            return jsonify({
                'success': False,
                'error': result.get('error', 'Unknown error')
            }), 500
            
    except Exception as e:
        print(f"âŒ PDF extraction error: {e}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': f'PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }), 500


if __name__ == '__main__':
    print("ğŸš€ GenGen Python API Server starting...")
    print("ğŸ“ Transcript API: GET /api/transcript/<video_id>")
    print("ğŸ§  Question Generation API: POST /api/generate-questions")
    print("ğŸ“„ PDF OCR API: POST /api/pdf/extract")
    app.run(host='0.0.0.0', port=3001, debug=True)
